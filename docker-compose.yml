version: '3.8'

networks:
  app_network:
    driver: bridge

services:
  tf_base:
    build:
      context: ./docker/base-tf
    image: deepanshu0903/nst_app:tf-base
    networks:
      - app_network

  ### 2) Frontend Service
  frontend:
    build: ./frontend
    image: deepanshu0903/nst_app:frontend
    depends_on:
      - tf_base
      - routing_service
    ports:
      - "80:80"
    networks:
      - app_network

  ### 3) Routing Service
  routing_service:
    build: ./routing_service
    image: deepanshu0903/nst_app:routing_service
    depends_on:
      - tf_base
      - inference-service-model1
      - inference-service-model2
      - inference-service-model3
      - inference-service-model4
    ports:
      - "8000:8000"
    volumes:
      - ${HOST_PERSISTENT_STORAGE}:/persistent_storage
    environment:
      PYTHONUNBUFFERED: 1
    networks:
      - app_network

  ### 4) Inference Service – Model 1
  inference-service-model1:
    build: ./inference_services/model1
    image: deepanshu0903/nst_app:inference_service_model1
    depends_on:
      - tf_base
    ports:
      - "8001:8000"
    volumes:
      - ${HOST_PERSISTENT_STORAGE}:/persistent_storage
    environment:
      PYTHONUNBUFFERED: 1
    networks:
      - app_network

  ### 5) Inference Service – Model 2
  inference-service-model2:
    build: ./inference_services/model2
    image: deepanshu0903/nst_app:inference_service_model2
    depends_on:
      - tf_base
    ports:
      - "8002:8000"
    volumes:
      - ${HOST_PERSISTENT_STORAGE}:/persistent_storage
    environment:
      PYTHONUNBUFFERED: 1
    networks:
      - app_network

  ### 6) Inference Service – Model 3
  inference-service-model3:
    build: ./inference_services/model3
    image: deepanshu0903/nst_app:inference_service_model3
    depends_on:
      - tf_base
    ports:
      - "8003:8000"
    volumes:
      - ${HOST_PERSISTENT_STORAGE}:/persistent_storage
    environment:
      PYTHONUNBUFFERED: 1
    networks:
      - app_network

  ### 7) Inference Service – Model 4
  inference-service-model4:
    build: ./inference_services/model4
    image: deepanshu0903/nst_app:inference_service_model4
    depends_on:
      - tf_base
    ports:
      - "8004:8000"
    volumes:
      - ${HOST_PERSISTENT_STORAGE}:/persistent_storage
    environment:
      PYTHONUNBUFFERED: 1
    networks:
      - app_network

  ### 8) Fine-Tuning Service
  fine_tuning_service:
    build: ./fine_tuning_service
    image: deepanshu0903/nst_app:fine_tuning_service
    depends_on:
      - tf_base
    ports:
      - "8005:8000"
    volumes:
      - ${HOST_PERSISTENT_STORAGE}:/persistent_storage
    environment:
      PYTHONUNBUFFERED: 1
    networks:
      - app_network
